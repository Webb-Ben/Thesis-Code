{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.rcParams.update({'figure.figsize': (10,6)})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Import  datasets\n",
    "\n",
    "1. Import training ('data/lab4-400-training.csv') and testing ('data/lab4-100-testing.csv') datasets into separate matrices. Use [genfromtxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html) or your data class.\n",
    "2. The column x is the independent variable.  Columns y1, y2, and y3 are dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "--------------------------------------\n",
    "Your results should look like\n",
    "--------------------------------------\n",
    "A first 5 rows:\n",
    "[[ 0.86084 -0.62216  3.93574 11.60028]\n",
    " [-0.30754  0.00447  4.675    8.86444]\n",
    " [ 0.77201 -0.79127  3.94762 10.83111]\n",
    " [-0.71808 -0.75327 11.83894  5.23568]\n",
    " [-0.28735  0.01856  8.7937   8.49431]]\n",
    "AT first 5 rows:\n",
    "[[-0.91878 -0.9357  22.11518  4.98345]\n",
    " [-0.92811 -1.16687 18.58222  3.34313]\n",
    " [-0.96837 -1.36751 13.3575   3.65102]\n",
    " [-0.96436 -1.62782 13.88831  4.08888]\n",
    " [-0.97014 -1.2789  24.96344  3.74772]]\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. 3 dimensional polynomial regression\n",
    "\n",
    "### 1a. Make a polynomial matrices\n",
    "\n",
    "1. Make a polynomial matrices for the training dataset using the independent variable\n",
    "    2. Create a matrix of [ones](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html), Ap, with the same number of rows as the training dataset and 4 columns\n",
    "    5. Update the second column to be the respective x column, the third column to be the respective x column squared, and the fourth column to be the respective x column cubed.\n",
    "    1. Print the first 5 rows of the matrix\n",
    "2. Make a polynomial matrix for the test dataset\n",
    "    3. Create a matrix of [ones](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html), ATp, with the same number of rows as the test dataset and 4 columns\n",
    "    5. Like in the step above, update the second column to be the respective x column, the third column to be the respective x column squared, and the fourth column to be the respective x column cubed.\n",
    "    1. Print the first 5 rows of the matrix\n",
    "1. Make a polynomial matrix to graph the prediction line\n",
    "    1. For graphing create a [linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html), line_x, from the minimum(x)-.1  value to the maximum(x)+.1 value with 100 steps\n",
    "    2. Create a matrix of [ones](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html), lineM_x, with the same number of rows as the training dataset and 4 columns\n",
    "    5. Like in the step above, update the second column to be the respective x column, the third column to be the respective x column squared, and the fourth column to be the respective x column cubed.\n",
    "    1. Print the first 5 rows of the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "--------------------------------------\n",
    "Your results should look like\n",
    "--------------------------------------\n",
    "Ap first 5 rows\n",
    "[[ 1.       0.86084  0.74104  0.63792]\n",
    " [ 1.      -0.30754  0.09458 -0.02909]\n",
    " [ 1.       0.77201  0.596    0.46012]\n",
    " [ 1.      -0.71808  0.51564 -0.37027]\n",
    " [ 1.      -0.28735  0.08257 -0.02373]]\n",
    "ATp first 5 rows\n",
    "[[ 1.      -0.91878  0.84417 -0.77561]\n",
    " [ 1.      -0.92811  0.86139 -0.79946]\n",
    " [ 1.      -0.96837  0.93773 -0.90807]\n",
    " [ 1.      -0.96436  0.92999 -0.89685]\n",
    " [ 1.      -0.97014  0.94118 -0.91308]]\n",
    "lineM_x first 5 rows\n",
    "[[ 1.      -1.00188  1.00377 -1.00566]\n",
    " [ 1.      -0.98052  0.96142 -0.9427 ]\n",
    " [ 1.      -0.95916  0.91999 -0.88242]\n",
    " [ 1.      -0.9378   0.87947 -0.82477]\n",
    " [ 1.      -0.91644  0.83987 -0.76969]]\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Calculate 3 dimensional polynomial regression\n",
    "1.  Use [linalg.lstsq]() from scipy to calculate and print the weights, residuals and rank for the dependent variable y1. \n",
    "2.  Calculate and print the $R^2$ value.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "--------------------------------------\n",
    "Your results should look like\n",
    "--------------------------------------\n",
    "c: [-0.15511 -0.96979 -0.24675  1.61541]\n",
    "residuals: 136.56714157926723\n",
    "rank: 4\n",
    "r-squared: 0.11595609001119211\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Testing and prediction\n",
    "\n",
    "1. calculate the $R^2$ for the linear regressions ability predict the test dataset\n",
    "    1.  Multiply ATp with the weights to get the predicted values\n",
    "    2.  Calculate the $R^2$ value and print it for each dependent variable.\n",
    "    > $R^2 = 1 - \\frac{\\sum_i \\left (y_i - \\hat{y}_i \\right )^2}{\\sum_i \\left (y_i - \\bar{y} \\right )^2}$ <br> <br> $y_i$ are the dependent variable values from the test dataset <br> $\\bar{y}_i$ is the mean of the dependent variable values from the test dataset <br> $\\hat{y}_i$ is the y values *predicted* by the regression\n",
    "\n",
    "2. Print the $R^2$ for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "--------------------------------------\n",
    "Your results should look like\n",
    "--------------------------------------\n",
    "r2 test: 0.4431027176546438\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Graph Results\n",
    "2. In one graph\n",
    "    1. Graph the training data as a scatter plot.\n",
    "    1. Graph the test dataset as a scatter plot.\n",
    "    1. Graph the prediction line with line_x as the dependent variable and multiplying lineM_x with the weights for the independent variable.\n",
    "    1. Include a title (with the two $R^2$ values), axis labels, and a legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Explore different polynomial degrees\n",
    "\n",
    "Using the above code as a starting out place calculate the polynomial regression for the datasets with different polynomial degrees\n",
    "\n",
    "### 2a.  Make 3 polynomial matrices: 1 for the training dataset, 1 for the test dataset and 1 for the prediction line\n",
    "1. Create a matrix of [ones](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html), Ap, with the same number of rows as the training dataset and 10 columns\n",
    "1. Create a matrix of [ones](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html), ATp, with the same number of rows as the testing dataset and 10 columns\n",
    "1. Create a matrix of [ones](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html), lineM_x, with the same number of rows as line_x and 10 columns\n",
    "1. For each matrix update the second column to be the respective x column, the third column to be the respective x column squared, and the fourth column to be the respective x column cubed, and so on to the 10th column \n",
    "1. Print the first row of each matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "--------------------------------------\n",
    "Your results should look like\n",
    "--------------------------------------\n",
    "Ap first row\n",
    "[[1.      0.86084 0.74104 0.63792 0.54915 0.47273 0.40694 0.35031 0.30156 0.2596 ]]\n",
    "ATp first row\n",
    "[[ 1.      -0.91878  0.84417 -0.77561  0.71261 -0.65474  0.60156 -0.55271 0.50782 -0.46658]]\n",
    "lineM_x first row\n",
    "[[ 1.      -1.00188  1.00377 -1.00566  1.00755 -1.00945  1.01135 -1.01325 1.01516 -1.01707]]\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Calculate multiple dimensional polynomial regression\n",
    "\n",
    "1.  Calculate the polynomial regression for 1st degree through 10th degree\n",
    "    1.  Using scipy's [linalg.lstsq]() to calculate the weights, residuals and rank. \n",
    "    2.  Calculate and print the $R^2$ value using the residual.\n",
    "    2.  Calculate the $R^2$ for the linear regressions ability predict the test dataset.\n",
    "        1. Multiply ATp with the weights to get the predicted values and calculate the $R^2$ value\n",
    "    1. Add to the plot the prediction line with line_x as the dependent variable and multiplying lineM_x with the weights as the independent variable.  Include the rank, $R^2$ value for the training data and the test data in the label for the line.\n",
    "2. Graph the results. \n",
    "    1. Graph the training data as a scatter plot.\n",
    "    1. Graph the test dataset as a scatter plot.\n",
    "    1. Include a title, axis labels, and a legend.\n",
    "    1. Draw the legend outside of the plot using the parameter bbox_to_anchor=(1.01, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.  Graph the datasets with the best polynomial regression\n",
    "\n",
    "1.  Review your results from Task 2 (graph and $R^2$ results) and choose the best polynomial degree.\n",
    "2.  Graph the training data, test data and best line representing the best polynomial degree.\n",
    "    1.  Include axis labels, and legend and a title (with rank and $R^2$ values for the training data and the test data).\n",
    "3.  Explain your results from Task 2, which polynomial degree you chose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:  Complete Task 2b and 3 using y2 and the dependent variable\n",
    "\n",
    "1.  Copy code from Task 2b and modify y and yT to use y2 as the dependent dataset.\n",
    "1.  Review your results and choose the best polynomial degree.\n",
    "2.  Copy code from Task 3 and modify y and yT to use y2 as the dependent dataset.\n",
    "3.  Explain your results, which polynomial degree you chose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Complete Task 2b and 3 using y3 and the dependent variable\n",
    "\n",
    "1.  Copy code from Task 2b and modify y and yT to use y3 as the dependent dataset.\n",
    "1.  Review your results and choose the best polynomial degree.\n",
    "2.  Copy code from Task 3 and modify y and yT to use y3 as the dependent dataset.\n",
    "3.  Explain your results, which polynomial degree you chose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
